/*
  Copyright (c) 2021, Oracle and/or its affiliates.

  This software is dual-licensed to you under the Universal Permissive License
  (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
  2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
  either license.

  If you elect to accept the software under the Apache License, Version 2.0,
  the following applies:

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

     https://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
*/

package org.apache.spark.sql.sqlmacros

import org.apache.spark.sql.catalyst.{expressions => sparkexpr}

trait Tuples { self: ExprTranslator =>

  import macroUniverse._

  object TupleConstruct {
    /**
       Generated by:
       {{{
       println((for(i <- 2 until 23) yield s"""val tup${i}ApplySym = typeOf[scala.Tuple${i}.type].member(TermName("apply"))""").mkString("\n"))
       }}}
       in scala shell
     */

    val tup2ApplySym = typeOf[scala.Tuple2.type].member(TermName("apply"))
    val tup3ApplySym = typeOf[scala.Tuple3.type].member(TermName("apply"))
    val tup4ApplySym = typeOf[scala.Tuple4.type].member(TermName("apply"))
    val tup5ApplySym = typeOf[scala.Tuple5.type].member(TermName("apply"))
    val tup6ApplySym = typeOf[scala.Tuple6.type].member(TermName("apply"))
    val tup7ApplySym = typeOf[scala.Tuple7.type].member(TermName("apply"))
    val tup8ApplySym = typeOf[scala.Tuple8.type].member(TermName("apply"))
    val tup9ApplySym = typeOf[scala.Tuple9.type].member(TermName("apply"))
    val tup10ApplySym = typeOf[scala.Tuple10.type].member(TermName("apply"))
    val tup11ApplySym = typeOf[scala.Tuple11.type].member(TermName("apply"))
    val tup12ApplySym = typeOf[scala.Tuple12.type].member(TermName("apply"))
    val tup13ApplySym = typeOf[scala.Tuple13.type].member(TermName("apply"))
    val tup14ApplySym = typeOf[scala.Tuple14.type].member(TermName("apply"))
    val tup15ApplySym = typeOf[scala.Tuple15.type].member(TermName("apply"))
    val tup16ApplySym = typeOf[scala.Tuple16.type].member(TermName("apply"))
    val tup17ApplySym = typeOf[scala.Tuple17.type].member(TermName("apply"))
    val tup18ApplySym = typeOf[scala.Tuple18.type].member(TermName("apply"))
    val tup19ApplySym = typeOf[scala.Tuple19.type].member(TermName("apply"))
    val tup20ApplySym = typeOf[scala.Tuple20.type].member(TermName("apply"))
    val tup21ApplySym = typeOf[scala.Tuple21.type].member(TermName("apply"))
    val tup22ApplySym = typeOf[scala.Tuple22.type].member(TermName("apply"))

    val arrAssocSym = typeOf[scala.Predef.ArrowAssoc[_]].member(TermName("$minus$greater"))

    /**
      cases generated by
      {{{
        for (i <- 3 until 23) yield {
          val patStr = (for (j <- 1 until i + 1) yield s"$$a_$j").mkString("(", ", ", ")")
          val treeSeq = (for (j <- 1 until i + 1) yield s"a_$j").mkString("Seq(", ", ", ")")
          s"""case q"${patStr}" if t.symbol == tup${i}ApplySym =>
                CatalystExpressions.unapplySeq(${treeSeq}).
                  map(es => sparkexpr.CreateStruct(es))""".stripMargin
        }
      }}}
      */

    // scalastyle:off line.size.limit

    def unapply(t: mTree): Option[sparkexpr.Expression] =
      t match {
        case q"($l, $r)" if t.symbol == tup2ApplySym =>
          CatalystExpressions.unapplySeq(Seq(l, r)).
            map(es => sparkexpr.CreateStruct(es))
        case q"Predef.ArrowAssoc[$_]($l).->[$_]($r)" if t.symbol == arrAssocSym =>
          CatalystExpressions.unapplySeq(Seq(l, r)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3)" if t.symbol == tup3ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4)" if t.symbol == tup4ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5)" if t.symbol == tup5ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6)" if t.symbol == tup6ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7)" if t.symbol == tup7ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8)" if t.symbol == tup8ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9)" if t.symbol == tup9ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10)" if t.symbol == tup10ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11)" if t.symbol == tup11ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12)" if t.symbol == tup12ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13)" if t.symbol == tup13ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14)" if t.symbol == tup14ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14, $a_15)" if t.symbol == tup15ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14, a_15)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14, $a_15, $a_16)" if t.symbol == tup16ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14, a_15, a_16)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14, $a_15, $a_16, $a_17)" if t.symbol == tup17ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14, a_15, a_16, a_17)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14, $a_15, $a_16, $a_17, $a_18)" if t.symbol == tup18ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14, a_15, a_16, a_17, a_18)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14, $a_15, $a_16, $a_17, $a_18, $a_19)" if t.symbol == tup19ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14, a_15, a_16, a_17, a_18, a_19)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14, $a_15, $a_16, $a_17, $a_18, $a_19, $a_20)" if t.symbol == tup20ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14, a_15, a_16, a_17, a_18, a_19, a_20)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14, $a_15, $a_16, $a_17, $a_18, $a_19, $a_20, $a_21)" if t.symbol == tup21ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14, a_15, a_16, a_17, a_18, a_19, a_20, a_21)).
            map(es => sparkexpr.CreateStruct(es))
        case q"($a_1, $a_2, $a_3, $a_4, $a_5, $a_6, $a_7, $a_8, $a_9, $a_10, $a_11, $a_12, $a_13, $a_14, $a_15, $a_16, $a_17, $a_18, $a_19, $a_20, $a_21, $a_22)" if t.symbol == tup22ApplySym =>
          CatalystExpressions.unapplySeq(Seq(a_1, a_2, a_3, a_4, a_5, a_6, a_7, a_8, a_9, a_10, a_11, a_12, a_13, a_14, a_15, a_16, a_17, a_18, a_19, a_20, a_21, a_22)).
            map(es => sparkexpr.CreateStruct(es))
        case _ => None
      }
  }
}